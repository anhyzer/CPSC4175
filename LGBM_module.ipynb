{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed011fd8-6d4d-4925-a7d5-b7ceb37d87f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import lightgbm\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_recall_curve\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "093906fa-c894-46f2-9ea6-e36d6734de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"framingham.csv\")\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12f61674-2d8b-4262-b3a3-b3f7ec1a03e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC from CV: 0.9972\n",
      "1 ROC AUC from CV: 0.996730\n",
      "2 ROC AUC from CV: 0.998367\n",
      "3 ROC AUC from CV: 0.998196\n",
      "4 ROC AUC from CV: 0.997225\n",
      "5 ROC AUC from CV: 0.996186\n",
      "6 ROC AUC from CV: 0.996509\n",
      "7 ROC AUC from CV: 0.996854\n",
      "STD ROC AUC from CV: 0.0008\n",
      "MCC: 0.4426\n",
      "Test ROC AUC: 0.9046\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       832\n",
      "           1       0.33      0.62      0.43        16\n",
      "\n",
      "    accuracy                           0.97       848\n",
      "   macro avg       0.66      0.80      0.71       848\n",
      "weighted avg       0.98      0.97      0.97       848\n",
      "\n",
      "Feature male: 0.0090\n",
      "Feature age: 0.0950\n",
      "Feature education: 0.1190\n",
      "Feature currentSmoker: 0.0282\n",
      "Feature cigsPerDay: 0.0673\n",
      "Feature BPMeds: 0.0129\n",
      "Feature prevalentStroke: 0.0000\n",
      "Feature prevalentHyp: 0.0100\n",
      "Feature totChol: 0.1306\n",
      "Feature sysBP: 0.1082\n",
      "Feature diaBP: 0.0948\n",
      "Feature BMI: 0.0823\n",
      "Feature heartRate: 0.1145\n",
      "Feature glucose: 0.1177\n",
      "Feature TenYearCHD: 0.0103\n",
      "\n",
      "Actual positives:\n",
      "16\n",
      "\n",
      "False Positives:\n",
      "20\n",
      "\n",
      "True positives:\n",
      "10\n",
      "\n",
      "False negatives:\n",
      "6\n",
      "\n",
      "True negatives:\n",
      "812\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with median\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Impute categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Split the dataset 80/20\n",
    "train_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Isolate the features and target\n",
    "features_train = train_df.drop(columns=\"diabetes\")\n",
    "target_train = train_df[\"diabetes\"]\n",
    "features_test = test_df.drop(columns=\"diabetes\")\n",
    "target_test = test_df[\"diabetes\"]\n",
    "\n",
    "# Set up ratio\n",
    "train_data = lightgbm.Dataset(train_df, label=target_train)\n",
    "valid_data = lightgbm.Dataset(test_df, label=target_test)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)\n",
    "\n",
    "# Define model parameters focusing on high recall\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 63,\n",
    "    #'feature_fraction': 0.5,\n",
    "    #'bagging_fraction': 0.5,\n",
    "    #'bagging_freq': 20,\n",
    "    'verbose': -1,\n",
    "    #'max_depth': 15,\n",
    "    'learning_rate': 0.02,\n",
    "    #'objective': 'binary:logistic',\n",
    "    #'n_estimators': 40\n",
    "}\n",
    "\n",
    "# Initialize and train model\n",
    "# model_lgbm = lightgbm.train(params, train_data, num_boost_round=5000) #, early_stopping_rounds =50)\n",
    "model = lightgbm.LGBMClassifier(**params)\n",
    "\n",
    "#y_train_pred = model_lgbm.predict(train_df)\n",
    "#y_valid_pred = model_lgbm.predict(test_df)\n",
    "#print(\"AUC Train: {:.4f}\\nAUC Valid:  {:.4f}\".format(roc_auc_score(target_train, y_train_pred),\n",
    "            #                                         roc_auc_score(target_test, y_valid_pred)))\n",
    "\n",
    "# Cross-validation using the resampled training data\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "roc_auc_scores = cross_val_score(model, features_train_resampled, target_train_resampled, cv=cv, scoring=\"roc_auc\")\n",
    "print(f\"Mean ROC AUC from CV: {roc_auc_scores.mean():.4f}\")\n",
    "s = 1\n",
    "for i in roc_auc_scores:\n",
    "    print(f\"{s} ROC AUC from CV: {i:4f}\")\n",
    "    s+=1\n",
    "print(f\"STD ROC AUC from CV: {roc_auc_scores.std():.4f}\")\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "model.fit(features_train_resampled, target_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_proba = model.predict_proba(features_test)[:, 1]\n",
    "roc_auc = roc_auc_score(target_test, y_pred_proba)\n",
    "y_pred = model.predict(features_test)\n",
    "print(f\"MCC: {matthews_corrcoef(target_test, y_pred):.4f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, y_pred))\n",
    "\n",
    "# Display feature importances\n",
    "importances = model.feature_importances_\n",
    "jsum = 0\n",
    "for i, j in enumerate(importances):\n",
    "    jsum = j+jsum\n",
    "for i, j in enumerate(importances):\n",
    "    print(f\"Feature {model.feature_name_[i]}: {j/jsum:.4f}\")\n",
    "\n",
    "# Display comparative results of actual v. false v. true predictions\n",
    "actual_positives = test_df[target_test == 1]\n",
    "false_positive_rows = test_df[(target_test == 0) & (y_pred == 1)]\n",
    "true_positive_rows = test_df[(target_test == 1) & (y_pred == 1)]\n",
    "false_negative_rows = test_df[(target_test == 1) & (y_pred == 0)]\n",
    "true_negative_rows = test_df[(target_test == 0) & (y_pred == 0)]\n",
    "\n",
    "print(f\"\\nActual positives:\\n{len(actual_positives)}\\n\")\n",
    "print(f\"False Positives:\\n{len(false_positive_rows)}\\n\")\n",
    "print(f\"True positives:\\n{len(true_positive_rows)}\\n\")\n",
    "print(f\"False negatives:\\n{len(false_negative_rows)}\\n\")\n",
    "print(f\"True negatives:\\n{len(true_negative_rows)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d68358b4-8b7c-4e5d-8dae-792f7e9edafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC from CV: 0.9973\n",
      "1 ROC AUC from CV: 0.995805\n",
      "2 ROC AUC from CV: 0.996905\n",
      "3 ROC AUC from CV: 0.998070\n",
      "4 ROC AUC from CV: 0.997254\n",
      "5 ROC AUC from CV: 0.998476\n",
      "6 ROC AUC from CV: 0.997789\n",
      "7 ROC AUC from CV: 0.996926\n",
      "STD ROC AUC from CV: 0.0008\n",
      "MCC: 0.5771\n",
      "Test ROC AUC: 0.9006\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       832\n",
      "           1       0.50      0.69      0.58        16\n",
      "\n",
      "    accuracy                           0.98       848\n",
      "   macro avg       0.75      0.84      0.78       848\n",
      "weighted avg       0.98      0.98      0.98       848\n",
      "\n",
      "Feature male: 0.0255\n",
      "Feature age: 0.1003\n",
      "Feature education: 0.1440\n",
      "Feature currentSmoker: 0.0177\n",
      "Feature cigsPerDay: 0.0763\n",
      "Feature BPMeds: 0.0077\n",
      "Feature prevalentStroke: 0.0000\n",
      "Feature prevalentHyp: 0.0061\n",
      "Feature sysBP: 0.1400\n",
      "Feature diaBP: 0.1074\n",
      "Feature BMI: 0.0913\n",
      "Feature heartRate: 0.1223\n",
      "Feature glucose: 0.1577\n",
      "Feature TenYearCHD: 0.0035\n",
      "\n",
      "Actual positives:\n",
      "16\n",
      "\n",
      "False Positives:\n",
      "11\n",
      "\n",
      "True positives:\n",
      "11\n",
      "\n",
      "False negatives:\n",
      "5\n",
      "\n",
      "True negatives:\n",
      "821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with median\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Impute categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Split the dataset 80/20\n",
    "train_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Isolate the features and target\n",
    "features_train = train_df.drop(columns=\"diabetes\").drop(columns=\"totChol\")\n",
    "target_train = train_df[\"diabetes\"]\n",
    "features_test = test_df.drop(columns=\"diabetes\").drop(columns=\"totChol\")\n",
    "target_test = test_df[\"diabetes\"]\n",
    "\n",
    "# Set up ratio\n",
    "train_data = lightgbm.Dataset(train_df, label=target_train)\n",
    "valid_data = lightgbm.Dataset(test_df, label=target_test)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)\n",
    "\n",
    "# Define model parameters focusing on high recall\n",
    "params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'is_unbalance': 'true',\n",
    "    'boosting': 'gbdt',\n",
    "    'num_leaves': 63,\n",
    "    #'feature_fraction': 0.5,\n",
    "    #'bagging_fraction': 0.5,\n",
    "    #'bagging_freq': 20,\n",
    "    'verbose': -1,\n",
    "    #'max_depth': 15,\n",
    "    'learning_rate': 0.02,\n",
    "    #'objective': 'binary:logistic',\n",
    "    #'n_estimators': 40\n",
    "}\n",
    "\n",
    "# Initialize and train model\n",
    "# model_lgbm = lightgbm.train(params, train_data, num_boost_round=5000) #, early_stopping_rounds =50)\n",
    "model = lightgbm.LGBMClassifier(**params)\n",
    "\n",
    "#y_train_pred = model_lgbm.predict(train_df)\n",
    "#y_valid_pred = model_lgbm.predict(test_df)\n",
    "#print(\"AUC Train: {:.4f}\\nAUC Valid:  {:.4f}\".format(roc_auc_score(target_train, y_train_pred),\n",
    "            #                                         roc_auc_score(target_test, y_valid_pred)))\n",
    "\n",
    "# Cross-validation using the resampled training data\n",
    "cv = StratifiedKFold(n_splits=7, shuffle=True, random_state=42)\n",
    "roc_auc_scores = cross_val_score(model, features_train_resampled, target_train_resampled, cv=cv, scoring=\"roc_auc\")\n",
    "print(f\"Mean ROC AUC from CV: {roc_auc_scores.mean():.4f}\")\n",
    "s = 1\n",
    "for i in roc_auc_scores:\n",
    "    print(f\"{s} ROC AUC from CV: {i:4f}\")\n",
    "    s+=1\n",
    "print(f\"STD ROC AUC from CV: {roc_auc_scores.std():.4f}\")\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "model.fit(features_train_resampled, target_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_proba = model.predict_proba(features_test)[:, 1]\n",
    "roc_auc = roc_auc_score(target_test, y_pred_proba)\n",
    "y_pred = model.predict(features_test)\n",
    "print(f\"MCC: {matthews_corrcoef(target_test, y_pred):.4f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, y_pred))\n",
    "\n",
    "# Display feature importances\n",
    "importances = model.feature_importances_\n",
    "jsum = 0\n",
    "for i, j in enumerate(importances):\n",
    "    jsum = j+jsum\n",
    "for i, j in enumerate(importances):\n",
    "    print(f\"Feature {model.feature_name_[i]}: {j/jsum:.4f}\")\n",
    "\n",
    "# Display comparative results of actual v. false v. true predictions\n",
    "actual_positives = test_df[target_test == 1]\n",
    "false_positive_rows = test_df[(target_test == 0) & (y_pred == 1)]\n",
    "true_positive_rows = test_df[(target_test == 1) & (y_pred == 1)]\n",
    "false_negative_rows = test_df[(target_test == 1) & (y_pred == 0)]\n",
    "true_negative_rows = test_df[(target_test == 0) & (y_pred == 0)]\n",
    "\n",
    "print(f\"\\nActual positives:\\n{len(actual_positives)}\\n\")\n",
    "print(f\"False Positives:\\n{len(false_positive_rows)}\\n\")\n",
    "print(f\"True positives:\\n{len(true_positive_rows)}\\n\")\n",
    "print(f\"False negatives:\\n{len(false_negative_rows)}\\n\")\n",
    "print(f\"True negatives:\\n{len(true_negative_rows)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046a60e6-806b-4eb6-9fde-b681effa774f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fd51a-3320-4e2c-8066-83ddbf1bc89f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (CPSC4176)",
   "language": "python",
   "name": "cpsc4175"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
