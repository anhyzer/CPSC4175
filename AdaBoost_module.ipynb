{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a697ff3-9339-4de9-9e90-79545492a94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score, precision_recall_curve, precision_score, recall_score\n",
    "from sklearn.metrics import matthews_corrcoef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e50cf6c-6ece-4f7c-a2f3-0c11d9b314b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "#from sklearnex import patch_sklearn \n",
    "from IPython.display import clear_output\n",
    "#patch_sklearn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36804ba1-b5c8-49b7-9b42-4c1f01fd9e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = os.path.join(\"framingham.csv\")\n",
    "df = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d6e2f4f-cf9e-4b71-900c-4b0039b5d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = 15\n",
    "min_m_d = 15\n",
    "max_m_d = 30\n",
    "inc_m_d = 1\n",
    "r_s = 21\n",
    "m_l_n = 16\n",
    "min_m_l_n = 5\n",
    "max_m_l_n = 30\n",
    "inc_m_l_n = 1\n",
    "n_j = -1 #const\n",
    "n_e = 20\n",
    "min_n_e = 20\n",
    "max_n_e = 200\n",
    "inc_n_e = 5\n",
    "l_r = .56\n",
    "min_l_r = 0.02\n",
    "max_l_r = 1.00\n",
    "inc_l_r = 0.02\n",
    "\n",
    "highest_pra_sofar = [0,0,0]\n",
    "bests=[]\n",
    "near_bests=[]\n",
    "best_sofar = [0,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca251520-97eb-45e4-8fc1-dbfac2fad324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Impute numerical columns with median\n",
    "for col in numerical_cols:\n",
    "    df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "# Impute categorical columns with mode\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Split the dataset 80/20\n",
    "train_df, test_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "# Isolate the features and target\n",
    "features_train = train_df.drop(columns=\"diabetes\")\n",
    "target_train = train_df[\"diabetes\"]\n",
    "features_test = test_df.drop(columns=\"diabetes\")\n",
    "target_test = test_df[\"diabetes\"]\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=r_s)\n",
    "features_train_resampled, target_train_resampled = smote.fit_resample(features_train, target_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e59afd-2184-48ca-8c53-a4948d83e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runThroughHP(m_d, n_e, m_l_n, l_r):\n",
    "    # Initialize and train model\n",
    "    tree = []\n",
    "    tree.append(DecisionTreeClassifier(max_depth=m_d, random_state=r_s))\n",
    "    tree.append(RandomForestClassifier(n_estimators=n_e, max_leaf_nodes=m_l_n, n_jobs=-1, random_state=r_s))\n",
    "    #svc=SVC(probability=True)\n",
    "    \n",
    "    # Create adaboost classifer object\n",
    "    abc = AdaBoostClassifier(n_estimators=n_e, estimator=tree[1], learning_rate=l_r, random_state=r_s)\n",
    "    model = abc.fit(features_train,target_train)\n",
    "    \n",
    "    \n",
    "    # Cross-validation using the resampled training data\n",
    "    cv = StratifiedKFold(n_splits=8, shuffle=True, random_state=r_s)\n",
    "    roc_auc_scores = cross_val_score(model, features_train_resampled, target_train_resampled, cv=cv, scoring=\"roc_auc\")\n",
    "    \n",
    "    # Train the model on the resampled training data\n",
    "    model.fit(features_train_resampled, target_train_resampled)\n",
    "    \n",
    "    # Evaluate on the test set\n",
    "    y_pred_proba = model.predict_proba(features_test)[:, 1]\n",
    "    roc_auc = roc_auc_score(target_test, y_pred_proba)\n",
    "    y_pred = model.predict(features_test)\n",
    "    ps = precision_score(target_test, y_pred)\n",
    "    rs = recall_score(target_test, y_pred)\n",
    "    a_s = accuracy_score(target_test, y_pred)\n",
    "    if(ps > .75 and rs == 1.00):\n",
    "        bests.append([a_s, m_d, n_e, m_l_n, l_r])\n",
    "    elif(ps > .6 and rs >= 0.875):\n",
    "        near_bests.append([a_s, m_d, n_e, m_l_n, l_r])\n",
    "    global highest_pra_sofar\n",
    "    global best_sofar\n",
    "    if((rs) > highest_pra_sofar[1] or (ps > highest_pra_sofar[0] and rs == highest_pra_sofar[1])):\n",
    "        highest_pra_sofar = [ps,rs,a_s]\n",
    "        best_sofar = [a_s, m_d, n_e, m_l_n, l_r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2084cb52-94d6-4994-a30e-07575597ad60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Count: 5854\n",
      " max_depth: 15\n",
      " n_estimators: 40\n",
      " max_leaf_nodes: 24\n",
      " learning_rate 0.46\n",
      " Best P,R,A so far: [0.36363636363636365, 0.75, 0.9705188679245284]\n",
      " best so far: [0.9705188679245284, 15, 30, 28, 0.02]\n",
      " Near Bests: 0\n",
      " Bests: 0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(min_m_d, max_m_d, inc_m_d):\n",
    "    for j in range(min_n_e, max_n_e, inc_n_e):\n",
    "        for k in range(min_m_l_n, max_m_l_n, inc_m_l_n):\n",
    "            for l in np.arange(min_l_r, max_l_r, inc_l_r):\n",
    "                runThroughHP(i,j,k,l)\n",
    "                clear_output(wait=True)\n",
    "                count+=1\n",
    "                print(f\" Count: {count}\\n max_depth: {i}\\n n_estimators: {j}\\n max_leaf_nodes: {k}\\n learning_rate {l}\\n Best P,R,A so far: {highest_pra_sofar}\\n best so far: {best_sofar}\\n Near Bests: {len(near_bests)}\\n Bests: {len(bests)}\")\n",
    "print(\"bests:\")\n",
    "print(bests)\n",
    "print(\"near bests:\")\n",
    "print(near_bests)\n",
    "\n",
    "best_acc = []\n",
    "if len(bests) > 0:\n",
    "    for i in bests:\n",
    "        best_acc.append(i[0])\n",
    "    np_bests = np.array(best_acc)\n",
    "    \n",
    "    highestacc_index = np.where(a == np_bests.max())\n",
    "    \n",
    "    m_d = bests[highestacc_index][1]\n",
    "    n_e = bests[highestacc_index][2]\n",
    "    m_l_n = bests[highestacc_index][3]\n",
    "    l_r = bests[highestacc_index][4]\n",
    "elif len(near_bests) > 0:\n",
    "    for i in near_bests:\n",
    "        best_acc.append(i[0])\n",
    "    np_bests = np.array(best_acc)\n",
    "    \n",
    "    highestacc_index = np.where(a == np_bests.max())\n",
    "    \n",
    "    m_d = near_bests[highestacc_index][1]\n",
    "    n_e = near_bests[highestacc_index][2]\n",
    "    m_l_n = near_bests[highestacc_index][3]\n",
    "    l_r = near_bests[highestacc_index][4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1c17486-5257-4ed5-951d-58d6b153dfc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ROC AUC from CV: 0.9990\n",
      "MCC: 0.5356\n",
      "Test ROC AUC: 0.8724\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "Non-diabetic       0.99      0.99      0.99       832\n",
      "    Diabetic       0.48      0.62      0.54        16\n",
      "\n",
      "    accuracy                           0.98       848\n",
      "   macro avg       0.73      0.81      0.77       848\n",
      "weighted avg       0.98      0.98      0.98       848\n",
      "\n",
      "Feature male: 0.0137\n",
      "Feature age: 0.0770\n",
      "Feature education: 0.1498\n",
      "Feature currentSmoker: 0.0396\n",
      "Feature cigsPerDay: 0.0775\n",
      "Feature BPMeds: 0.0172\n",
      "Feature prevalentStroke: 0.0023\n",
      "Feature prevalentHyp: 0.0074\n",
      "Feature totChol: 0.0828\n",
      "Feature sysBP: 0.0883\n",
      "Feature diaBP: 0.0679\n",
      "Feature BMI: 0.0618\n",
      "Feature heartRate: 0.0859\n",
      "Feature glucose: 0.2180\n",
      "Feature TenYearCHD: 0.0109\n",
      "\n",
      "Actual positives:\n",
      "16\n",
      "\n",
      "False Positives:\n",
      "11\n",
      "\n",
      "True positives:\n",
      "10\n",
      "\n",
      "False negatives:\n",
      "6\n",
      "\n",
      "True negatives:\n",
      "821\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train model\n",
    "tree = []\n",
    "tree.append(DecisionTreeClassifier(max_depth=m_d, random_state=r_s))\n",
    "tree.append(RandomForestClassifier(n_estimators=n_e, max_leaf_nodes=m_l_n, n_jobs=-1, random_state=r_s))\n",
    "#svc=SVC(probability=True)\n",
    "\n",
    "# Create adaboost classifer object\n",
    "abc = AdaBoostClassifier(n_estimators=n_e, estimator=tree[1], learning_rate=l_r, random_state=r_s)\n",
    "model = abc.fit(features_train,target_train)\n",
    "\n",
    "\n",
    "# Cross-validation using the resampled training data\n",
    "cv = StratifiedKFold(n_splits=8, shuffle=True, random_state=r_s)\n",
    "roc_auc_scores = cross_val_score(model, features_train_resampled, target_train_resampled, cv=cv, scoring=\"roc_auc\")\n",
    "print(f\"Mean ROC AUC from CV: {roc_auc_scores.mean():.4f}\")\n",
    "\n",
    "# Train the model on the resampled training data\n",
    "model.fit(features_train_resampled, target_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred_proba = model.predict_proba(features_test)[:, 1]\n",
    "roc_auc = roc_auc_score(target_test, y_pred_proba)\n",
    "y_pred = model.predict(features_test)\n",
    "print(f\"MCC: {matthews_corrcoef(target_test, y_pred):.4f}\")\n",
    "print(f\"Test ROC AUC: {roc_auc:.4f}\")\n",
    "print(\"Classification Report:\\n\", classification_report(target_test, y_pred, target_names=[\"Non-diabetic\", \"Diabetic\"]))\n",
    "\n",
    "# Display feature importances\n",
    "importances = model.feature_importances_\n",
    "for i, j in enumerate(importances):\n",
    "    print(f\"Feature {model.feature_names_in_[i]}: {j:.4f}\")\n",
    "\n",
    "# Display comparative results of actual v. false v. true predictions\n",
    "actual_positives = test_df[target_test == 1]\n",
    "false_positive_rows = test_df[(target_test == 0) & (y_pred == 1)]\n",
    "true_positive_rows = test_df[(target_test == 1) & (y_pred == 1)]\n",
    "false_negative_rows = test_df[(target_test == 1) & (y_pred == 0)]\n",
    "true_negative_rows = test_df[(target_test == 0) & (y_pred == 0)]\n",
    "\n",
    "print(f\"\\nActual positives:\\n{len(actual_positives)}\\n\")\n",
    "print(f\"False Positives:\\n{len(false_positive_rows)}\\n\")\n",
    "print(f\"True positives:\\n{len(true_positive_rows)}\\n\")\n",
    "print(f\"False negatives:\\n{len(false_negative_rows)}\\n\")\n",
    "print(f\"True negatives:\\n{len(true_negative_rows)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08c2838e-01c3-4e8f-804f-33dd2b90d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report with Optimized Threshold:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.00      0.00       832\n",
      "           1       0.02      1.00      0.04        16\n",
      "\n",
      "    accuracy                           0.02       848\n",
      "   macro avg       0.51      0.50      0.02       848\n",
      "weighted avg       0.98      0.02      0.00       848\n",
      "\n",
      "\n",
      "Actual positives:\n",
      "16\n",
      "\n",
      "False Positives:\n",
      "831\n",
      "\n",
      "True positives:\n",
      "16\n",
      "\n",
      "False negatives:\n",
      "0\n",
      "\n",
      "True negatives:\n",
      "1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_scores = model.predict_proba(features_test)[:, 1]\n",
    "\n",
    "# Get precision-recall values for different thresholds\n",
    "precision, recall, thresholds = precision_recall_curve(target_test, y_scores)\n",
    "\n",
    "# Find the threshold where recall is maximized (this is a naive approach, and in real applications you'd want a balance)\n",
    "optimal_threshold = thresholds[np.argmax(recall)]\n",
    "\n",
    "# Classify using the new threshold\n",
    "y_pred_optimal = np.where(y_scores > optimal_threshold, 1, 0)\n",
    "\n",
    "print(\"Classification Report with Optimized Threshold:\\n\", classification_report(target_test, y_pred_optimal))\n",
    "\n",
    "\n",
    "# Display comparative results of actual v. false v. true predictions\n",
    "actual_positives = test_df[target_test == 1]\n",
    "false_positive_rows = test_df[(target_test == 0) & (y_pred_optimal == 1)]\n",
    "true_positive_rows = test_df[(target_test == 1) & (y_pred_optimal == 1)]\n",
    "false_negative_rows = test_df[(target_test == 1) & (y_pred_optimal == 0)]\n",
    "true_negative_rows = test_df[(target_test == 0) & (y_pred_optimal == 0)]\n",
    "\n",
    "print(f\"\\nActual positives:\\n{len(actual_positives)}\\n\")\n",
    "print(f\"False Positives:\\n{len(false_positive_rows)}\\n\")\n",
    "print(f\"True positives:\\n{len(true_positive_rows)}\\n\")\n",
    "print(f\"False negatives:\\n{len(false_negative_rows)}\\n\")\n",
    "print(f\"True negatives:\\n{len(true_negative_rows)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdbd529-11b9-4ee7-a779-a05a8562fce2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
